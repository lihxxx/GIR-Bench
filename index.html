<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <title>GIR-Bench ‚Äî Project Page</title>
    <meta name="description" content="GIR-Bench: A reasoning-centric benchmark for unified multimodal models." />
    <link rel="stylesheet" href="css/styles.css" />
</head>

<body>
    <header>
        <div class="container nav">
            <div class="left">
                <img src="static/logo.png" class="logo-img" alt="GIR-Bench logo" loading="eager">
                <div class="brand">GIR-Bench</div>
                <!-- make nav horizontally scrollable to avoid wrapping/misalignment -->
                <nav class="nav-links">
                    <a href="#motivation" class="pill">Motivation</a>
                    <a href="#overview" class="pill">Overview</a>
                    <a href="#qualitative" class="pill">Qualitative</a>
                    <a href="#quantitative" class="pill">Quantitative</a>
                    <a href="#resources" class="pill">Resources</a>
                </nav>
            </div>
            <div class="right">
                <button id="theme-btn" class="btn ghost" aria-label="Toggle theme">üåó Theme</button>
                <a class="btn" href="#bibtex">BibTeX</a>
                <!-- TODO: replace with real link -->
                <a class="btn primary" href="#" target="_blank" rel="noopener">Code & Data</a>
            </div>
        </div>
    </header>

    <main class="container">
        <!-- HERO -->
        <section class="hero">
            <div class="badge">Benchmark Project Page</div>
            <h1 class="title">GIR-Bench: Versatile Benchmark for Generating Images with Reasoning</h1>
            <p class="subtitle">Reasoning-centric evaluation of <b>multimodal unified models</b> across <b>Understanding
                    ‚Äì Generation Consistency (UGC)</b>, <b>Text-to-Image</b>, and <b>Editing</b>, revealing the
                persistent gap between reasoning and faithful generation.</p>
            <div class="row">
                <!-- TODO: replace links -->
                <a class="btn primary" href="#" target="_blank">Paper (PDF)</a>
                <a class="btn ghost" href="#leaderboard">Leaderboard</a>
                <a class="btn ghost" href="#">Huggingface Data</a>
                <a class="btn ghost" href="#">Github Code</a>
                <!-- <a class="btn ghost" href="#demo">Interactive Demo</a> -->
            </div>
            <div class="hero-cards">
                <div class="card">
                    <h4>Highlights</h4>
                    <ul>
                        <li>Three views: Reasoning-driven Understanding ‚Üî Generation Consistency / T2I / Editing</li>
                        <li>Objective, task-specific, interpretable evaluation metrics, less LMM-as-a-Judge bias</li>
                        <li>21 models and meaningful analysis; shows reasoning ‚Üí generation/editing transfer bottleneck
                        </li>
                    </ul>
                </div>
                <div class="card">
                    <h4>What‚Äôs inside</h4>
                    <ul>
                        <li>Understanding ‚Üî Generation Consistency: 300 real-world entities across zoology, botany, and
                            geograph</li>
                        <li>T2I: 300 logical reasoning entities across numerical, layout, and text rendering</li>
                        <li>Editing: 370 planning and reasoning-driven entities across puzzle, sudoku, and reasoning
                            perception</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- MOTIVATION -->
        <section id="motivation">
            <h2>Motivation</h2>
            <p class="lead">
                Most existing evaluations focus on shallow text‚Äìimage alignment and lean on ‚ÄúLMM-as-a-Judge.‚Äù
                <b></b>GIR-Bench</b> instead probes complex, implicit reasoning in <b>unified multimodal models</b>
                across <b>Understanding‚ÄìGeneration Consistency</b>, <b>Text-to-Image</b>, and <b>Editing</b>, using
                <b>objective, task-specific, interpretable metrics</b> for a more comprehensive and fair assessment.
                Large-scale analyses show that while unified models outperform generation-only systems on
                reasoning-heavy tasks, they still struggle to reliably translate reasoning into <b>faithful visual
                    outputs</b>.
            </p>
        </section>

        <!-- OVERVIEW -->
        <section id="overview">
            <div class="grid-2">
                <div>
                    <h2>Benchmark Overview</h2>
                    <p>Three sub-benchmarks cover parsing <span class="chip">knowledge</span> and <span
                            class="chip">constraints</span>, and reliably injecting reasoning into generation/editing.
                    </p>
                    <div class="tabs" role="tablist">
                        <button class="tab active" data-tab="uni" role="tab">GIR-Bench-UGC</button>
                        <button class="tab" data-tab="t2i" role="tab">GIR-Bench-T2I</button>
                        <button class="tab" data-tab="edit" role="tab">GIR-Bench-Edit</button>
                    </div>
                    <div class="tabpanes">
                        <div id="pane-uni" class="active">
                            <p><b>Goal:</b> Compare understanding vs generation for the same real-world entity. Implicit
                                descriptions trigger generation; real images are used for understanding evaluation.</p>
                            <ul>
                                <li>Domains: zoology, botany, geography (world knowledge)</li>
                                <li>Metric: DINOv3 similarity (generation); VQA accuracy (understanding)</li>
                            </ul>
                        </div>
                        <div id="pane-t2i">
                            <p><b>Goal:</b> Reasoning-driven T2I (numerical, layout, text rendering).</p>
                            <ul>
                                <li>Numerical: logic/counting; exact-match on detected counts</li>
                                <li>Layout: verify rules via detected boxes (e.g., left‚Üîright)</li>
                                <li>Text: implicit slogan ‚Üí OCR substring score (<code>s<sub>wc</sub></code>)</li>
                            </ul>
                        </div>
                        <div id="pane-edit">
                            <p><b>Goal:</b> Reasoning-driven editing (puzzle reassembly, sudoku completion, reasoning
                                perception segmentation).</p>
                            <ul>
                                <li>Puzzle: normalized FID</li>
                                <li>Sudoku: OCR digits then grid-level accuracy</li>
                                <li>Perception: IoU of predicted mask vs ground truth</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div>
                    <figure class="figure column" aria-label="Overview Figure">
                        <!-- TODO: replace with an overview illustration -->
                        <img class="example" src="static/overview.jpg" alt="Overview Figure" width="1000" height="1000"
                            loading="lazy" id="overview-img">
                        <div>
                            <span class="chip">Click to enlarge the image.</span>
                        </div>
                    </figure>
                </div>
            </div>
        </section>

        <!-- Qualitative Results -->
        <section id="qualitative">
            <h2>Qualitative Results</h2>
            <p class="lead">Preview typical cases for the three sub-benchmarks. </p>

            <div class="tabs" role="tablist">
                <button class="tab active" data-target="#ex-uni" role="tab">GIR-Bench-UGC</button>
                <button class="tab" data-target="#ex-t2i" role="tab">GIR-Bench-T2I</button>
                <button class="tab" data-target="#ex-edit" role="tab">GIR-Bench-Edit</button>
            </div>

            <div class="tabpanes">
                <!-- UGC -->
                <div id="ex-uni" class="active">
                    <div class="grid-2">
                        <figure class="figure column">
                            <img class="example" src="static/ugc_case.jpeg" alt="UGC: understanding vs generation case"
                                loading="lazy">
                            <div>
                                <span class="chip">Click to enlarge the image.</span>
                            </div>
                        </figure>
                        <div class="card">
                            <h4>Understanding ‚Üî Generation</h4>
                            <ul>
                                <li>Implicit prompt triggers generation </li>
                                <li>300 real-world entities from Internet and open datasets</li>
                                <li>Verify if models use shared knowledge for understanding and generation</li>
                                <li>Domains: zoology, botany, geography</li>
                            </ul>
                            <h4>Evaluation</h4>
                            <ul>
                                <li>Real image used for understanding</li>
                                <li>DINOv3 similarity (generation)</li>
                                <li>VQA accuracy (understanding)</li>
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- T2I -->
                <div id="ex-t2i">
                    <div class="grid-2">
                        <figure class="figure column">
                            <img class="example" src="static/t2i_case.jpeg"
                                alt="T2I: numerical, layout, and text rendering" loading="lazy">
                            <div>
                                <span class="chip">Click to enlarge the image.</span>
                            </div>
                        </figure>
                        <div class="card">
                            <h4>Reasoning-driven T2I</h4>
                            <ul>
                                <li>300 complex logical reasoning entities </li>
                                <li>Not only requires retrieving world knowledge</li>
                                <li>But also applying precise logical reasoning to meet specified constraints</li>
                            </ul>
                            <h4>Evaluation</h4>
                            <ul>
                                <li>Numerical: exact-match on detected counts</li>
                                <li>Layout: verify rules via detected boxes (e.g., left‚Üîright)</li>
                                <li>Text: implicit slogan ‚Üí OCR substring score
                            </ul>
                        </div>
                    </div>
                </div>

                <!-- EDIT -->
                <div id="ex-edit">
                    <div class="grid-2">
                        <figure class="figure column">
                            <img class="example" src="static/edit_case.jpeg"
                                alt="Editing: puzzle, sudoku, and perception" loading="lazy">
                            <div>
                                <span class="chip">Click to enlarge the image.</span>
                            </div>
                        </figure>
                        <div class="card">
                            <h4>Reasoning-driven Editing</h4>
                            <ul>
                                <li>370 planning and reasoning-driven entities</li>
                                <li>Evaluate spatial perception, logical reasoning, and complex reasoning chains</li>
                            </ul>
                            <h4>Evaluation</h4>
                            <ul>
                                <li>Puzzle: normalized FID</li>
                                <li>Sudoku: OCR digits ‚Üí grid accuracy</li>
                                <li>Perception: IoU of prediction vs GT</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </section>


        <!-- RESULTS -->
        <section id="quantitative">
            <h2>Quantitative Results</h2>
            <p class="lead">Unified models outperform generaion-only baselines overall, yet reliable transfer from
                <b>reasoning</b> to <b>generation</b> remains the key bottleneck.
            </p>

            <h3 id="leaderboard">Leaderboard</h3>
            <div class="row" style="align-items:center;">
                <span class="chip">Click headers to sort</span>
                <span class="chip">UCG = Understanding ‚Äì Generation Consistency</span>
                <span class="chip">UCG-U = understanding, UCG-G = generation</span>
                <label for="typeFilter" class="pill"
                    style="border:none;background:transparent;padding:0 0 0 8px;">Type:</label>
                <select id="typeFilter" class="pill" aria-label="Filter by type">
                    <option value="all">All</option>
                    <option value="Und">Und</option>
                    <option value="Gen">Gen</option>
                    <option value="Edit">Edit</option>
                    <option value="Unified">Unified</option>
                </select>
            </div>
            <table id="lb">
                <thead>
                    <tr>
                        <th><span class="sort" data-key="model">Model ‚¨ç</span></th>
                        <th><span class="sort" data-key="type">Type ‚¨ç</span></th>
                        <th><span class="sort" data-key="ucg_u">UCG-U ‚¨ç</span></th>
                        <th><span class="sort" data-key="ucg_g">UCG-G ‚¨ç</span></th>
                        <th><span class="sort" data-key="t2i">T2I ‚¨ç</span></th>
                        <th><span class="sort" data-key="edit">Edit ‚¨ç</span></th>
                    </tr>
                </thead>
                <tbody>
                    <!-- Understanding only -->
                    <tr>
                        <td>Qwen2.5VL-7B</td>
                        <td>Und</td>
                        <td>0.978</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Qwen2.5-VL-32B</td>
                        <td>Und</td>
                        <td>0.976</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>GPT-5</td>
                        <td>Und</td>
                        <td>0.994</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Gemini-2.5-Flash</td>
                        <td>Und</td>
                        <td>0.997</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>

                    <!-- Generation only -->
                    <tr>
                        <td>SD-3.5-Large</td>
                        <td>Gen</td>
                        <td>-</td>
                        <td>0.288</td>
                        <td>0.134</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>HiDream-I1-Full</td>
                        <td>Gen</td>
                        <td>-</td>
                        <td>0.378</td>
                        <td>0.153</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>FLUX.1-schnell</td>
                        <td>Gen</td>
                        <td>-</td>
                        <td>0.292</td>
                        <td>0.159</td>
                        <td>-</td>
                    </tr>

                    <!-- Editing only -->
                    <tr>
                        <td>FLUX.1-Kontext-dev</td>
                        <td>Edit</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>0.105</td>
                    </tr>
                    <tr>
                        <td>ICEdit</td>
                        <td>Edit</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>0.095</td>
                    </tr>
                    <tr>
                        <td>Step1X-Edit</td>
                        <td>Edit</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>0.070</td>
                    </tr>

                    <!-- Unified -->
                    <tr>
                        <td>Show-o2-7B</td>
                        <td>Unified</td>
                        <td>0.935</td>
                        <td>0.198</td>
                        <td>0.139</td>
                        <td>0.054</td>
                    </tr>
                    <tr>
                        <td>Janus-Pro-7B</td>
                        <td>Unified</td>
                        <td>0.874</td>
                        <td>0.211</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>BLIP3o-NEXT-SFT-3B</td>
                        <td>Unified</td>
                        <td>0.974</td>
                        <td>0.263</td>
                        <td>-</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Ovis-U1-3B</td>
                        <td>Unified</td>
                        <td>0.909</td>
                        <td>0.244</td>
                        <td>0.163</td>
                        <td>0.095</td>
                    </tr>
                    <tr>
                        <td>OmniGen2</td>
                        <td>Unified</td>
                        <td>0.952</td>
                        <td>0.294</td>
                        <td>0.140</td>
                        <td>0.073</td>
                    </tr>
                    <tr>
                        <td>UniPic2-Metaquery-9B</td>
                        <td>Unified</td>
                        <td>-</td>
                        <td>0.301</td>
                        <td>0.135</td>
                        <td>0.133</td>
                    </tr>
                    <tr>
                        <td>UniWorld-V1</td>
                        <td>Unified</td>
                        <td>-</td>
                        <td>0.302</td>
                        <td>0.139</td>
                        <td>0.054</td>
                    </tr>
                    <tr>
                        <td>BAGEL-7B</td>
                        <td>Unified</td>
                        <td>0.937</td>
                        <td>0.295</td>
                        <td>0.169</td>
                        <td>0.098</td>
                    </tr>
                    <tr>
                        <td>BAGEL-7B w/ CoT</td>
                        <td>Unified</td>
                        <td>0.968</td>
                        <td>0.341</td>
                        <td>0.272</td>
                        <td>0.140</td>
                    </tr>
                    <tr>
                        <td>Qwen-Image</td>
                        <td>Unified</td>
                        <td>-</td>
                        <td>0.429</td>
                        <td>0.224</td>
                        <td>-</td>
                    </tr>
                    <tr>
                        <td>Qwen-Image-Edit</td>
                        <td>Unified</td>
                        <td>-</td>
                        <td>-</td>
                        <td>-</td>
                        <td>0.158</td>
                    </tr>
                    <tr>
                        <td>Gemini-2.5-Flash-Image</td>
                        <td>Unified</td>
                        <td>-</td>
                        <td>0.595</td>
                        <td>0.642</td>
                        <td>0.340</td>
                    </tr>
                    <tr>
                        <td>GPT-Image-1</td>
                        <td>Unified</td>
                        <td>-</td>
                        <td>0.689</td>
                        <td>0.610</td>
                        <td>0.350</td>
                    </tr>
                </tbody>
            </table>
        </section>


        <!-- RESOURCES -->
        <section id="resources">
            <h2>Resources</h2>
            <div class="grid-3">
                <div class="card">
                    <h4>Paper</h4>
                    <!-- TODO: replace -->
                    <a href="#" class="btn">PDF</a>
                </div>
                <div class="card">
                    <h4>Code & Data</h4>
                    <!-- TODO: replace -->
                    <a href="#" class="btn">GitHub</a>
                </div>
                <div class="card">
                    <h4>Contact</h4>
                    <div class="row">
                        <a class="btn mailto" data-user="liyaowei01" data-domain="google.com"
                            rel="nofollow noopener">liyaowei01 [at] gmail.com</a>
                    </div>
                    <div class="row">
                        <a class="btn mailto" data-user="lihxxxxxx" data-domain="gmail.com"
                            rel="nofollow noopener">lihxxxxxx [at] gmail.com</a>
                    </div>
                </div>
            </div>
        </section>

        <!-- BIBTEX -->
        <section id="bibtex">
            <h2>BibTeX</h2>
            <div class="row">
                <button id="copyBib" class="btn">Copy</button>
                <span id="copyState" class="chip">Ready</span>
            </div>
            <pre><code id="bib">
@article{girbench2025,
  title   = {GIR-Bench: Versatile Benchmark for Generating Images with Reasoning},
  author  = {Li, Hongxiang and Li, Yaowei and Lin, Bin and Niu, Yuwei and Yang, Yuhang and Huang, Xiaoshuang and Cai, Jiayin and Jiang, Xiaolong and Hu, Yao and Chen, Long},
  journal = {arXiv},
  year    = {2025},
  note    = {Reasoning-centric benchmark for unified multimodal models}
}
    </code></pre>
        </section>

        <!-- DEMO
        <section id="demo">
            <h2>Interactive Demo (optional)</h2>
            <p class="lead">Let users input implicit prompts to see model generations and script-based evaluation
                (counts/layout/text score).</p>
            <div class="figure">Demo Placeholder</div>
        </section> -->
    </main>

    <footer class="container" style="padding:28px 0 60px;">
        <div class="row" style="justify-content:space-between;">
            <span class="muted">¬© GIR-Bench 2025</span>
            <span class="muted"><a href="#top">Back to top ‚Üë</a></span>
        </div>
    </footer>

    <!-- Floating tools -->
    <div class="sticky-tools">
        <button class="btn tooltip" id="scrollTop" data-tip="Back to top">‚Üë</button>
    </div>

    <script src="js/main.js" defer></script>
</body>

</html>